{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "You are given a string `s` and an array of strings `words` of **the same\n",
    "length**. Return all starting indices of substring(s) in `s` that is a\n",
    "concatenation of each word in `words` **exactly once** , **in any order** ,\n",
    "and **without any intervening characters**.\n",
    "\n",
    "You can return the answer in **any order**.\n",
    "\n",
    "\n",
    "\n",
    "**Example 1:**\n",
    "\n",
    "\n",
    "\n",
    "    Input: s = \"barfoothefoobarman\", words = [\"foo\",\"bar\"]\n",
    "    Output: [0,9]\n",
    "    Explanation: Substrings starting at index 0 and 9 are \"barfoo\" and \"foobar\" respectively.\n",
    "    The output order does not matter, returning [9,0] is fine too.\n",
    "\n",
    "\n",
    "**Example 2:**\n",
    "\n",
    "\n",
    "\n",
    "    Input: s = \"wordgoodgoodgoodbestword\", words = [\"word\",\"good\",\"best\",\"word\"]\n",
    "    Output: []\n",
    "\n",
    "\n",
    "**Example 3:**\n",
    "\n",
    "\n",
    "\n",
    "    Input: s = \"barfoofoobarthefoobarman\", words = [\"bar\",\"foo\",\"the\"]\n",
    "    Output: [6,9,12]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Constraints:**\n",
    "\n",
    "  * `1 <= s.length <= 104`\n",
    "  * `s` consists of lower-case English letters.\n",
    "  * `1 <= words.length <= 5000`\n",
    "  * `1 <= words[i].length <= 30`\n",
    "  * `words[i]` consists of lower-case English letters."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "find_word_concatenation (generic function with 1 method)"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "cell_type": "code",
   "source": [
    "# @lc code=start\n",
    "using LeetCode\n",
    "using DataStructures\n",
    "\n",
    "function find_word_concatenation(s::String, words::Vector{String})::Vector{Int}\n",
    "    (length(words) == 0 || length(words[1]) == 0) && return 0\n",
    "    words_map = counter(words)\n",
    "    results_indices = Int[]\n",
    "    word_len, words_count = length(words[1]), length(words)\n",
    "\n",
    "    for i in 1: (length(s) - word_len * words_count + 1)\n",
    "        words_seen = DefaultDict{String, Int}(0)\n",
    "        for j in 0: words_count - 1\n",
    "            next_word_index = i + j * word_len\n",
    "            # Get the next word from the string\n",
    "            word = s[next_word_index: next_word_index + word_len - 1]\n",
    "            # Break if we don't need this word\n",
    "            !haskey(words_map, word) && break\n",
    "            # Add the word to the 'words_seen' map\n",
    "            words_seen[word] += 1\n",
    "            # No need to process further if the word has higher frequency than required\n",
    "            words_seen[word] > get(words_map, word, 0) && break\n",
    "\n",
    "            # Store index if we have found all the words\n",
    "            (j + 1 == words_count) && push!(results_indices, i)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return results_indices\n",
    "end\n",
    "# @lc code=end"
   ],
   "metadata": {},
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.4"
  },
  "kernelspec": {
   "name": "julia-1.6",
   "display_name": "Julia 1.6.4",
   "language": "julia"
  }
 },
 "nbformat": 4
}
